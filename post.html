<!DOCTYPE html>
<html>
<head>
	<title>Post Name</title>


	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1" />

	<link href="https://fonts.googleapis.com/css2?family=Russo+One&display=swap" rel="stylesheet">

	<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@500&display=swap" rel="stylesheet">

	<link rel="stylesheet" type="text/css" href="default.css">


	<style type="text/css">
		.img-container{
			max-width: 600px;
		}

		img{
			width: 100%
		}

	</style>

</head>
<body>
	<div class="nav-wrapper">

		<!-- Link around dots-wrapper added after tutorial video -->
		<a href="index.html">
			<div class="dots-wrapper">
				<div id="dot-1" class="browser-dot"></div>
				<div id="dot-2" class="browser-dot"></div>
				<div id="dot-3" class="browser-dot"></div>
			</div>
		</a>

		<ul id="navigation">
			<li><a href="index.html#contact">Contact</a></li>

		</ul>
	</div>

	<div class="main-container">
		<br>

		<div class="img-container">
			<img src="images/face-mask.jpg">
		</div>
		
		<h3>Face Mask Detection Alert System</h3>

		<p>As no of covid-19 cases are increasing a lot in the country day-by-day. We must follow the social distancing. Not only social distancing there is another important parameter that we should consider that everyone should wear the mask when they go outside.By this parameter we can reduce the covid-19 cases. But many people are neglecting to wear the masks. By this no of cases are gradually increasing. To avoid such cases I am implementing the face mask detection alert system. The basic advantage of face mask detection alert system is that it identifies the person who is not wearing the mask.It will send an email to the authority that the person is not wearing the mask with his/her photo as an attachment. By this we can reduce the covid-19 cases for some extent.
		<br>
		<br>
		This kind of face mask detection alarm system has applications at Airports, Hotels, Public Buildings like Driving License Offices and other major places where we expect large public gatherings. We will be using Python, OpenCV, CNN, Keras framework with Tensorflow as backend for building the Deep Learning Convolutional Neural network model. We will be training this model on google col-lab using gpu instances. Model training of neural networks based deep learning models take less time to get trained on gpu instances. In this project we have the dataset that consists of 1376 images. In that 690 images are categorized as with mask and 686 images are categorized in to without mask. We have to train a model that detect that person is wearing a mask or not.
		<br>
		<br>
		<h5>STEPS FOR FACE RECOGNITION ALERT SYSTEM</h5>
		<br>
		<br>
		1. Configure working directory and Mount Google Drive to make use of Google Colab.
		<br>
		<br>
		2. Data Pre-processing to convert images to Grayscale and separate out labels and images.
		<br>
		<br>
		3. Build a convolutional Neural Network using Sequential API of Keras.
		<br>
		<br>
		4. Train the Face Mask Detection classifier on Image Data using Keras and Tensorflow as Backend.
		<br>
		<br>
		5. Evaluate the model to see the Loss and Accuracy in Graphical Form.
		<br>
		<br>
		6. Save or Serialize the Face Detection Classifier Model.
		<br>
		<br>
		7. Download the model on the Local System and load it in the program.
		<br>
		<br>
		8. Use the Live Webcam Video Stream to detect the face.
		<br>
		<br>
		9. Extract the region of Interest of the face.
		<br>
		<br>
		10. Engage the trained Facemask Detection Model to the face identified and determine if the person is wearing Mask or not.
		<br>
		<br>
		11. Throw a Warning message in terms of Pop Up window to highlight that Access Denied if the person did not wear the mask.
		<br>
		<br>
		12. Trigger an Email to the concerned person/authority alerting them if the person is not wearing the mask.
		<br>
		<br>
		</p>

		<h5>Technologies:</h5>
		<ul>
			<li>- Python</li>
			<li>- Pycharm Idle</li>
			<li>- Installation of few dependencies and packages</li>
			<li>- OpenCV</li>
		</ul>
		
		<div class="img-container">
			<img src="images/facemask-6.PNG">
		</div>
		
		<p>Using google colab first we need to change the runtime to gpu, because when you train your model your model will be trained on gpu instance. We need to mount our google drive so that we can access various files and dataset etc; that we will upload on google drive. Here we have set of configuration commands to setup necessary environment to mount to our google drive.</p>
		<div class="img-container">
			<img src="images/facemask-1.PNG">
		</div>

		<p>First we are importing the drive from google colab and we have mount function associated with the drive</p>
		<div class="img-container">
			<img src="images/facemask-2.PNG">
		</div>

		<p>We are importing necessary keras packages, numpy and Opencv2 packages that are needed for the face recognition alert system. We have to define the dimensions of single image as 112*112 pixels. I have defined the variables img_rows, img_cols stores the dimension values of the images. Then we are defining the two empty lists named images and labels. Images list will store all the images after we perform grayscale and resizing. Labels list will contain labels corresponding to the classes of the image. We are using the nested for loops first for loop is used for picking the each class directory namely with mask and without mask from google drive from the location of Data_Dir. Next for loop is used to get all the list of image files from specific directory. Once we get the individual image we are then using os.path.join method to join folderpath with that individual image. After we want to read that image using imread function. We have used try and except block for error handling. Inside the try block we are converting the image into grayscale and resizing the image into 112*112 pixels. Later we are appending that image in the images list before we are assigned it earlier. Corresponding category is appended to labels list and theexception block will handle any error occurs. Normalising the image by dividing with number 255 and reshaping the image array without changing the data of image array. Since our labels are in the form of with mask and without mask so we need to perform the one hot encoding so that our label data can be understood by our deep learning model. One hot encoder needs the data in integer encoded form. We are importing the label binarizer from sklearn .preprocessing package and creating the object of label binarizer and named it as lb. we are then using fit transform method to apply label binarizer on each label. Then we are using to_categorical method to convert labels to one hot encoded form and converting in to arrays using numpy arrays function. This is required because deep learning models understands the data in the form of vector or array form. Next we are dividing the train_test_split method to divide our images into training and test dataset. I have taken the size of test dataset to be 25%.  </p>
		<div class="img-container">
			<img src="images/facemask-3.PNG">
		</div>

		<div class="img-container">
			<img src="images/facemask-4.PNG">
		</div>

		<div class="img-container">
			<img src="images/facemask-5.PNG">
		</div>
		<h5>HOW COMPUTER READS THE IMAGE?</h5>
		<p>Consider if we have two images, one is black and white of 2*2 pixels and another one is 2*2 px of coloured image. Black and white image in convolutional neural networks is referred as 2D or 2-dimensional array. Coloured image is referred ad 3-d image. Each of the pixel in black and white image is 8-bit information. Every pixel having value ranging between 0-255. Here, 0-255 is intensity of colour where 255 is completely white pixel and 0 is completely black pixel and between we have grayscale of colours.</p>
		<p>Computers read this information to process the image. Every image is representation of 1’s and 0’s forming numbers 0 to 255 for each pixel. colour images is made up of 3 colours red, blue, green (RGB), so basically three layers so each of red, green and blue. So each of these colours have their own colour intensity, each having value ranging between 0-255. Computers combine these separate colours to find out the colour of the image. </p>
		<div class="img-container">
			<img src="images/facemask-7.PNG">
		</div>
		<h5>CONVOLUTION LAYER</h5>
		<p>Convolutional neural networks get trained on these images to recognize patterns and classify the image in the object accordingly. The name for detecting the patterns in the CNN model is Feature detector or kernel or filter. CNN use of the feature detector to detect the significant feature of the image data in order to provide predictions. Feature detector is simply a small matrix of weights</p>
		<div class="img-container">
			<img src="images/facemask-8.PNG">
		</div>
		<p>Now we have 2-D training image input on the left hand side and also feature detector on right hand side which is 3*3 matrix. It can be 5*5 or 7*7 matrix as well. But the most commonly used matrix is 3*3. The convolution operation is denoted by x in the circle. In order to do the convolution operation we want to put the feature detector on the input image and then we want to perform element wise multiplication of 9 pixel feature detector with the part of input which is currently on and then summing up the result in to a single output pixel. We are moving the whole feature detector on input image is called stride. Here we are performing the stride of 1px and we have a stride of 2 or 3px based on our requirement. By doing this we convert 2-d matrix of features in to another 2-d matrix of features of reduced size of that image. By doing this the shape of input image is modified by the feature detector. there by detecting the particular feature from the input image and get the result having information about that feature. That is called the feature map</p>
		<div class="img-container">
			<img src="images/facemask-9.PNG">
		</div>
		<h5>HOW WE CAN CONVOLUTION OPERATION FOR COLOURED IMAGES?</h5>
		<div class="img-container">
			<img src="images/facemask-10.PNG">
		</div>
		<p>Coloured image is referred as 3d-image. It contains the 3 channels RGB, Now here we want to perform feature detector having the size 3*3*3 and this feature detector should contains the 3 channels and perform multiplication on input image values and summing the result in to a single output pixel value and move the feature detector with help of stride value. After doing all the operations we can detect the particular features of an image.</p>
		<h5>Rectified Linear Unit (Relu layer):</h5>
		<p>Relu transform function only activates the node if the input is above certain quantity, while the input is below zero, the output is zero, but when the input rises above a certain threshold, it has linear relationship with dependent variable. In this layer we remove every negative values from the filtered images and replace it with zero. This is done to avoid the values summing up to zero.</p>
		<div class="img-container">
			<img src="images/facemask-11.PNG">
		</div>
		<h5>MAX POOLING LAYER</h5>
		<p>If we want our CNN model to recognize the object in an image correctly even the objects tilted, distorted, different light composition, textures etc; for that case max pooling layer is introduced. CNN model possess the property called spatial invariance which gives CNN flexibility to recognize an image features even if in object in the image has different lighting, orientation, distortion, background colour etc; Max pooling is also referred as sub-sampling or down-sampling layer</p>
		<div class="img-container">
			<img src="images/facemask-12.PNG">
		</div>
		<p>1. Pick a window size(usually 2 or 3)</p>
		<p>2. Pick a stride(Usually 2)</p>
		<p>3. Walk your window across your filtered images.</p>
		<p>4. For each window take the maximum value.</p>
		<p>By applying max-pooling we are reducing the dimensionality of each feature map there by getting rid of features. Reduction helps in size of faster processing during model training.</p>
		<div class="img-container">
			<img src="images/facemask-13.PNG">
		</div>
		<p>We convert Max pooling layered data of an image one long vector so that corresponding data can be easily read by the neural network by using flattening layer. Feeding the data as long vector to the neural network. Some of the artificial neural networks have dense layer as last layer which expects data in one-dimension. Last layer of CNN is classifier which is also known as dense layer, this is artificial neural network classifier, ANN classifier requires individual features just like any other classifiers, It needs feature vector Hence we need to convert the output of the convolution part or max-pooling part of CNN into a one dimensional feature vector, so it can be used by ANN. </p>
		</div>

</body>
</html>